{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/ISOTIPO-Color.jpg\" title=\"Title text\" width=\"20%\" />\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-479 Reconocimiento de patrones en minería de datos </h1>\n",
    "\n",
    "<H2 align='center'> Tarea 3 - Sistemas Recomendadores </H2>\n",
    "<H3 align='center'> Lucio Fondón Rebolledo - 201773610-0</H3>\n",
    "<H3 align='center'> Francisco Reyes Jainaga - 201773529-5</H3>\n",
    "<hr style=\"height:2px;border:none\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrucciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. La tarea debe ser desarrollada en parejas.  \n",
    "2. Los medios de consultas serán Aula y el canal de Discord oficial del curso. \n",
    "3. La tarea debe ser realizada en Jupyter Notebook (Python3) utilizando este archivo como base. \n",
    "4. Se evaluará la correcta implementación de los algoritmos de filtrado colaborativo aplicados a los datasets escogido por cada grupo, como también la comprensión de los fundamentos teóricos, ventajas y desventajas de cada técnica. \n",
    "5. El archivo de entrega debe denominarse T3_Apellido1_Apellido2.ipynb. De no respetarse este formato existirá un descuento de 30 puntos. \n",
    "6. La fecha de entrega es el lunes 2 de agosto a las 23:55 hrs, posterior a esto se descontará 1 punto por cada minuto de atraso.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Tarea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la tarea tendrán a su disposición los siguientes 3 datasets, <b> de las cuales tendrán que escoger 2 para realizar la implementación de su tarea. </b>\n",
    "\n",
    "   ### 1. MovieLens: \n",
    "   Es uno de los datasets más populares de recomendación y recopila las preferencias de usuarios de internet con respecto a películas que son evaluadas de 0 a 5 estrellas. Este dataset ha sido utilizado en diversos estudios de investigación en áreas como la recomendación personalizada y la psicología social.  \n",
    "* <b>Archivos: </b>\n",
    "    - ML_ratings.csv: contiene los ratings dados por usuarios a películas. Se compone por las columnas user_id, movie_id y rating. \n",
    "    - movies.csv: contiene la metadata sobre las películas. Incluye las columnas movie_id, title y genres (donde se encuentran los géneros de la película separados por \"|\"). \n",
    " \n",
    "* <b>Cantidad de ratings</b>: 100836\n",
    "* <b>Cantidad de usuarios</b>: 610\n",
    "* <b>Cantidad de películas</b>: 9724\n",
    "* <b>Calificación</b> 0 a 5 (valores enteros) \n",
    "\n",
    "Referencias: [Movielens Dataset](https://grouplens.org/datasets/movielens/) \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ML_ratings = pd.read_csv(\"ML_ratings.csv\")\n",
    "df_movies = pd.read_csv(\"movies.csv\")\n",
    "\n",
    "display(df_ML_ratings)\n",
    "display(df_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Book-Crossing: \n",
    "Es un datasets de ratings de libros recolectado por Cai-Nicolas Ziegler desde la <i>Book-Crossing community</i>. El dataset original contiene 1,149,780 ratings generados por 278,858 usuarios a 271,379 libros. \n",
    "\n",
    "* <b>Archivos</b>: \n",
    "    - BX_ratings.csv: contiene los ratings dados por usuarios a diferentes libros. Se compone de las columnas user_id, ISBN (identificador para los libros) y rating.\n",
    "    - books.csv: contiene los títulos de libros asociados a los códigos ISBN (utilizados como item_id). Se compone de las columnas ISBN y title. \n",
    "\n",
    "* <b>Cantidad de ratings</b>: 359263\n",
    "* <b>Cantidad de usuarios</b>: 10775\n",
    "* <b>Cantidad de libros</b>: 10773\n",
    "* <b>Calificación</b>: 0 a 10 (valores enteros)\n",
    "\n",
    "Referencias: [Book-Crossing Dataset](http://www2.informatik.uni-freiburg.de/~cziegler/BX/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BX_ratings = pd.read_csv(\"BX_ratings.csv\")\n",
    "df_books = pd.read_csv(\"books.csv\")\n",
    "\n",
    "display(df_BX_ratings)\n",
    "display(df_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Jester:     \n",
    "Es un dataset desarrollado por Ken Goldberg y su equipo en la Universidad de Berkeley, el cual contiene alrededor de 6 millones de ratings con respecto a 150 chistes cortos. \n",
    "* <b>Archivos</b>:\n",
    "    - JT_ratings.csv: contiene los ratings dados por usuarios a diferentes chistes cortos. Se compone por las columnas joke_id, user_id y rating. \n",
    "    - jokes.csv: contiene \n",
    "\n",
    "* <b>Cantidad de ratings</b>: 199900\n",
    "* <b>Cantidad de usuarios</b>: 1999\n",
    "* <b>Cantidad de chistes</b>: 100 \n",
    "* <b>Calificación</b>: -10 a 10 (valores reales)\n",
    "    \n",
    "Referencias: [Jester Dataset](http://eigentaste.berkeley.edu/dataset/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_JT_ratings = pd.read_csv(\"JT_ratings.csv\")\n",
    "df_jokes = pd.read_csv(\"jokes.csv\")\n",
    "\n",
    "display(df_JT_ratings)\n",
    "display(df_jokes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11227-020-03266-2/MediaObjects/11227_2020_3266_Fig1_HTML.png\" title=\"Title text\" width=\"60%\" />\n",
    "<center> <i> Figura 1. Collaborative Filtering. </i> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. User based Collaborative Filtering (40 puntos) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera parte de la tarea constará de las siguientes secciones: \n",
    "1. Implementación de un sistema de recomendación de filtro colaborativo basado en usuarios utilizando los k vecinos más cercanos. Para esta parte, se debe utilizar <b> similaridad coseno </b> como medida de similaridad entre el usuario objetivo y el resto de usuarios. Además, el parámetro k debe ser escogido por ustedes. \n",
    "\n",
    "2. Se ingresa nuevo usuario al sistema, se le pide que califique 10 productos (a elección) y a partir de eso se le realiza la recomendación de 5 productos que no ha calificado. Es importante que en su procedimiento se muestren las ids de los k vecinos más cercanos.  \n",
    "\n",
    "3. Concluir y responder las siguientes preguntas: \n",
    "\n",
    "   >a. ¿Cuáles fueron las 5 recomendaciones obtenidas? Analice y concluya respecto a estos resultados.  \n",
    "    \n",
    "   >b. ¿Qué cantidad de vecinos cercanos (k) se escogió para la recomendación? ¿En qué influye la elección de este parámetro? ¿Qué sucede a medida que aumenta este parámetro?\n",
    "    \n",
    "   >c. ¿Cuál era el porcentaje de <i>sparsity</i> de la matriz usuarios-items? ¿Cuáles son las desventajas de este enfoque? \n",
    "\n",
    "\n",
    "<i>Importante: Esto debe ser realizado para ambos datasets escogidos</i>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo P1\n",
    "\n",
    "Primero, definiremos funciones que nos servirán de ayuda para los dos datasets elegidos (__MovieLens__ y __Jester__). Definiremos una función que nos retorne los $k$ id's de los usuarios más similares respecto a un usuario objetivo y otra función que realizará la recomendación de las $n$ mejores películas para el usuario objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una función que nos retorne los usuarios más similares respecto a un usuario objetivo\n",
    "# Se utilizará (como es pedido) la similaridad coseno como métrica\n",
    "\n",
    "\"\"\"\n",
    "input\n",
    "user_id  : (int) id del usuario objetivo \n",
    "matrix   : (2D array) matriz de ratings entre los usuarios y los items con ratings\n",
    "k        : (int) k vecinos más cercanos\n",
    "\n",
    "output\n",
    "users    : (1D array) arreglo con las id's de los k usuarios más cercanos al usuario objetivo\n",
    "\"\"\"\n",
    "\n",
    "def similar_users(user_id, matrix, k=3):\n",
    "    user = matrix[matrix.index == user_id] # ratings usuario objetivo\n",
    "    other_users = matrix[matrix.index != user_id] # ratings resto de usuarios\n",
    "    \n",
    "    # Calculamos la similaridad coseno entre el usuario objetivo y el resto de ellos\n",
    "    similarities = cosine_similarity(user,other_users)[0].tolist()\n",
    "    \n",
    "    indices = other_users.index.tolist()\n",
    "    \n",
    "    # Diccionario donde la llave es el id de un usuario distinto al objetivo\n",
    "    # el valor es la similaridad coseno del usuario con el usuario objetivo\n",
    "    index_similarity = dict(zip(indices, similarities))\n",
    "        \n",
    "    # Ordenamos por similaridad de mayor a menor\n",
    "    index_similarity_sorted = sorted(index_similarity.items(), key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    # Escogemos los k primeros vecinos más cercanos (son los con mayor similitud con el usuario objetivo)\n",
    "    top_users_similarities = index_similarity_sorted[:k]\n",
    "    \n",
    "    # Obtenemos los id de los usuarios\n",
    "    users = [u[0] for u in top_users_similarities]\n",
    "    return users\n",
    "\n",
    "# Creamos función que nos retorne los n items con mejor recomendación para un usuario objetivo\n",
    "\n",
    "\"\"\"\n",
    "input\n",
    "user_id            : (int) id del usuario objetivo \n",
    "similar_user_ids   : (1D array) arreglo que contiene las id's de usuarios similares\n",
    "matrix             : (2D array) matriz de ratings entre los usuarios y los items con ratings\n",
    "dataset            : (string) string que corresponde al nombre del dataset que se utiliza\n",
    "n                  : (int) n items a recomendar para el usuario objetivo user_id\n",
    "\n",
    "output\n",
    "items_prediction   : (array) arreglo con las mejores n predicciones para el usuario objetivo\n",
    "\"\"\"\n",
    "\n",
    "def recommend_item(user_id, similar_user_ids, matrix, dataset, n=5):\n",
    "    # Obtenemos los vectores de los usuarios similares al usuario objetivo obtenidos con la función similar_users\n",
    "    similar_users = matrix[matrix.index.isin(similar_user_ids)]\n",
    "\n",
    "    # Calculamos el rating de los k usuarios más cercanos\n",
    "    similar_users = similar_users.mean(axis=0)\n",
    "    similar_users_df = pd.DataFrame(similar_users, columns=['mean'])\n",
    "        \n",
    "    # Obtenemos el vector del usuario objetivo\n",
    "    user_df = matrix[matrix.index == user_id]\n",
    "    user_df_transposed = user_df.transpose()\n",
    "    user_df_transposed.columns = ['rating']\n",
    "    \n",
    "    # Obtenemos los items que el usuario objetivo NO ha rateado\n",
    "    user_df_transposed = user_df_transposed[user_df_transposed['rating']==0]\n",
    "    items_not_rated = user_df_transposed.index.tolist()\n",
    "        \n",
    "    # Filtramos el rating promedio de los usuarios de los items no rateados por el usuario objetivo\n",
    "    similar_users_df_filtered = similar_users_df[similar_users_df.index.isin(items_not_rated)]\n",
    "   \n",
    "    # Ordenamos el dataframe de mayor a menor rating y obtenemos los n primeros\n",
    "    similar_users_df_ordered = similar_users_df.sort_values(by=['mean'], ascending=False)\n",
    "    top_n_items = similar_users_df_ordered.head(n)\n",
    "    top_n_items_indices = top_n_items.index.tolist()\n",
    "    \n",
    "    # Dependiendo del dataset usado, se utiliza el nombre correspondiente\n",
    "    item_id = ''\n",
    "    if dataset == 'movielens':\n",
    "        item_id = 'movie_id'\n",
    "        df_final = df_movies\n",
    "    elif dataset == 'jester':\n",
    "        item_id = 'joke_id'\n",
    "        df_final = df_jokes\n",
    "    \n",
    "    # Se consulta al dataset con los top n items seleccionados\n",
    "    items_prediction = df_final[df_final[item_id].isin(top_n_items_indices)]\n",
    "    \n",
    "    return items_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo P2\n",
    "\n",
    "Ahora, debemos ingresar un nuevo usuario al sistema y que califique 10 productos. Para esto, se realizará una función que realizará automáticamente esta calificación para los dos datasets escogidos. Éstos se escogerán de manera al azar, por lo que se seteará una semilla para poder replicar resultados y que la revisión sea más adecuada y fácil de realizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input\n",
    "dataset : (string) string que corresponde al nombre del dataset que se utiliza\n",
    "\n",
    "output\n",
    "df      : (pandas dataframe) dataframe con las 10 calificaciones agregadas\n",
    "\"\"\"\n",
    "\n",
    "def rate_10_products(dataset):\n",
    "    np.random.seed(0) # Se setea una semilla para poder replicar resultados\n",
    "    if dataset == 'movielens':\n",
    "        df = df_ML_ratings.copy()\n",
    "        \n",
    "        # Sacamos el id nuevo que tendrá el usuario, se le sumará +1 al último que se encuentre en el df\n",
    "        new_user_id = df.iloc[-1]['user_id'] + 1\n",
    "        \n",
    "        # Obtenemos todos los id de las películas\n",
    "        movie_ids = df['movie_id'].unique()\n",
    "        \n",
    "        # Seleccionamos al azar 10 películas para calificarlas\n",
    "        random_movies = np.random.choice(movie_ids, size=10, replace=False)\n",
    "        \n",
    "        # Generamos ratings de manera aleatoria en el rango de 0-5\n",
    "        random_ratings = np.random.randint(0, 6, size=10)\n",
    "        \n",
    "        # Diccionario con todos los valores generados\n",
    "        random_final = {\n",
    "            'user_id' : [new_user_id] * 10,\n",
    "            'movie_id' : random_movies,\n",
    "            'rating' : random_ratings,\n",
    "        }\n",
    "        \n",
    "        # Generamos un dataframe para los datos del usuario nuevo\n",
    "        df_random_ratings = pd.DataFrame(random_final)\n",
    "        \n",
    "        # Printearmos para ver qué películas calificó el usuario\n",
    "        print(\"El usuario con user_id de \" + str(new_user_id) + \" calificó las siguientes películas:\")\n",
    "        \n",
    "        for index, row in df_random_ratings.iterrows():\n",
    "            movie =  df_movies[df_movies['movie_id'] == row['movie_id']]['title'].item()\n",
    "            rating = row['rating']\n",
    "            print(\"Película: \" + movie + \" con rating \" + str(rating))\n",
    "        \n",
    "        # Agregamos los datos al df original\n",
    "        df = df.append(df_random_ratings)\n",
    "        \n",
    "        # Retornamos el nuevo df con los datos del nuevo usuario\n",
    "        return df\n",
    "        \n",
    "    elif dataset == 'jester':\n",
    "        df = df_JT_ratings.copy()\n",
    "        \n",
    "        # Sacamos el id nuevo que tendrá el usuario, se le sumará +1 al último que se encuentre en el df\n",
    "        new_user_id = df.iloc[-1]['user_id'] + 1\n",
    "        \n",
    "        # Obtenemos todos los id de las bromas\n",
    "        joke_ids = df['joke_id'].unique()\n",
    "        \n",
    "        # Seleccionamos al azar 10 bromas para calificarlas\n",
    "        random_jokes = np.random.choice(joke_ids, size=10, replace=False)\n",
    "        \n",
    "        # Generamos ratings de manera aleatoria en el rango de -10.0 a 10.0\n",
    "        random_ratings = np.random.uniform(-10.0, 10.0, 10).round(decimals=2)\n",
    "        \n",
    "        # Diccionario con todos los valores generados\n",
    "        random_final = {\n",
    "            'joke_id' : random_jokes,\n",
    "            'user_id' : [new_user_id] * 10,\n",
    "            'rating' : random_ratings,\n",
    "        }\n",
    "        \n",
    "        # Generamos un dataframe para los datos del usuario nuevo\n",
    "        df_random_ratings = pd.DataFrame(random_final)\n",
    "        \n",
    "        # Printearmos para ver qué películas calificó el usuario\n",
    "        print(\"El usuario con user_id de \" + str(new_user_id) + \" calificó las siguientes bromas: \")\n",
    "        \n",
    "        for index, row in df_random_ratings.iterrows():\n",
    "            movie =  df_jokes[df_jokes['joke_id'] == row['joke_id']]['joke_text'].item()\n",
    "            rating = row['rating']\n",
    "            print(\"Broma: \" + movie + \"\\n Con rating \" + str(rating) +\"\\n\")\n",
    "            print(\"-\" * 60)\n",
    "        # Agregamos los datos al df original\n",
    "        df = df.append(df_random_ratings)\n",
    "        \n",
    "        # Retornamos el nuevo df con los datos del nuevo usuario\n",
    "        return df\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MovieLens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, utilizaremos la función $\\texttt{rate_10_products}$ para crear un nuevo usuario al azar y que califique aleatoriamente 10 películas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_with_new_rating = rate_10_products('movielens')\n",
    "movies_with_new_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, debemos generar la matriz de ratings entre los usuarios y las películas rateadas, de tal forma que quede una matriz cuadrada $n x n$, en donde $n$ serían la cantidad de usuarios en el dataset, y los valores de la matriz será el rating del usuario $i$ con la película $j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rating_matrix_movies = movies_with_new_rating.pivot_table(index = 'user_id',columns = 'movie_id', values = 'rating').fillna(0)\n",
    "rating_matrix_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, solo debemos utilizar las funciones realizadas anteriormente para poder obtener las 5 recomendaciones pedidas. Se probarán con distintos valores de $k$, con el fin de poder concluir respecto a la elección de $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_user = 611\n",
    "similar_user_indices = similar_users(current_user, rating_matrix_movies, k=3)\n",
    "print(similar_user_indices)\n",
    "recommend_item(current_user, similar_user_indices, rating_matrix_movies, 'movielens')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "current_user = 611\n",
    "similar_user_indices = similar_users(current_user, rating_matrix_movies, k=5)\n",
    "print(similar_user_indices)\n",
    "recommend_item(current_user, similar_user_indices, rating_matrix_movies, 'movielens')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_user = 611\n",
    "similar_user_indices = similar_users(current_user, rating_matrix_movies, k=10)\n",
    "print(similar_user_indices)\n",
    "recommend_item(current_user, similar_user_indices, rating_matrix_movies, 'movielens')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_user = 611\n",
    "similar_user_indices = similar_users(current_user, rating_matrix_movies, k=30)\n",
    "print(similar_user_indices)\n",
    "recommend_item(current_user, similar_user_indices, rating_matrix_movies, 'movielens')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análogo a lo anterior, se realizan los mismos pasos anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "jokes_with_new_rating = rate_10_products('jester')\n",
    "jokes_with_new_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_matrix_jokes = jokes_with_new_rating.pivot_table(index = 'user_id',columns = 'joke_id', values = 'rating').fillna(0)\n",
    "rating_matrix_jokes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_user = 2000\n",
    "similar_user_indices = similar_users(current_user, rating_matrix_jokes, k=3)\n",
    "print(similar_user_indices)\n",
    "recommend_item(current_user, similar_user_indices, rating_matrix_jokes, 'jester')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_user = 2000\n",
    "similar_user_indices = similar_users(current_user, rating_matrix_jokes, k=5)\n",
    "print(similar_user_indices)\n",
    "recommend_item(current_user, similar_user_indices, rating_matrix_jokes, 'jester')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_user = 2000\n",
    "similar_user_indices = similar_users(current_user, rating_matrix_jokes, k=10)\n",
    "print(similar_user_indices)\n",
    "recommend_item(current_user, similar_user_indices, rating_matrix_jokes, 'jester')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_user = 2000\n",
    "similar_user_indices = similar_users(current_user, rating_matrix_jokes, k=30)\n",
    "print(similar_user_indices)\n",
    "recommend_item(current_user, similar_user_indices, rating_matrix_jokes, 'jester')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "current_user = 2000\n",
    "similar_user_indices = similar_users(current_user, rating_matrix_jokes, k=50)\n",
    "print(similar_user_indices)\n",
    "recommend_item(current_user, similar_user_indices, rating_matrix_jokes, 'jester')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo P3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Concluir y responder las siguientes preguntas: \n",
    "\n",
    "   >a. ¿Cuáles fueron las 5 recomendaciones obtenidas? Analice y concluya respecto a estos resultados.  \n",
    "    \n",
    "   >b. ¿Qué cantidad de vecinos cercanos (k) se escogió para la recomendación? ¿En qué influye la elección de este parámetro? ¿Qué sucede a medida que aumenta este parámetro?\n",
    "    \n",
    "   >c. ¿Cuál era el porcentaje de <i>sparsity</i> de la matriz usuarios-items? ¿Cuáles son las desventajas de este enfoque? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.- \n",
    "Con un k inicial de 3 vecinos los resultados para ambos dataset son: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_user = 611\n",
    "similar_user_indices = similar_users(current_user, rating_matrix_movies, k=3)\n",
    "print(similar_user_indices)\n",
    "recommend_item(current_user, similar_user_indices, rating_matrix_movies, 'movielens')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al comparar las cinco sugerencias locales, podemos ver una tendencia o inclinación por lo generos, como son Comedy, Drama y Romance, las cuales salen en casi todas las películas recomendadas. Por lo que podemos interpretar esto como los posibles gustos del usuario ingresado según por lo que el mismo califico dentro de sus 10 evaluaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_user = 2000\n",
    "similar_user_indices = similar_users(current_user, rating_matrix_jokes, k=3)\n",
    "print(similar_user_indices)\n",
    "recommend_item(current_user, similar_user_indices, rating_matrix_jokes, 'jester')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.-  \n",
    "Luego de una variacíon de los k vecinos a comparar al momento de entregar las recomendaciones, podemos ver que para ambos dataset al momento de aumentar el k existen recomendaciones que siguen apareciendo al ser de las mejores 5 opciones locales en esos momentos, como en el caso de la película Star Wars: Episode IV - A New Hope (1977), la cual aparece repetidas veces. Como tambien sugerencias que solo salen una vez, como en el dataset de jokes con la siguiente broma, 49\tA guy goes into confession and says to the pri..., la cual solo sale al momento de comparar 30 vecinos cercanos, probablemente eso ocurra ya que estaba bastante alejada de la persona a comparar, pero puede que si aumentamos la cantidad de vecinos esta mantenga su aparición como sugerencia. (Las 5 sugerencias de cada dataset con variaciones de vecinos estan señaladas en las celdas de arriba)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.-\n",
    "\n",
    "   > __R:__ El <i>sparsity</i> de una matriz $A$ se define como:\n",
    "   $$sparsity = 1 - \\frac{cantidad\\_no\\_ceros(A)}{total\\_elementos(A)}$$ \n",
    "   \n",
    "   > entonces, crearemos una función que nos ayudará a calcular lo anterior\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input\n",
    "A        : (pandas datafrane) matriz de ratings en forma de dataframe\n",
    "\n",
    "output\n",
    "sparsity : (double) valor del sparsity de la matriz\n",
    "\"\"\"\n",
    "def sparsity(A):\n",
    "    # Calculamos la cantidad de elementos no nulos de A\n",
    "    cantidad_no_ceros = np.count_nonzero(A)\n",
    "    \n",
    "    # Calculamos el total de elementos de A\n",
    "    total_elementos = A.size\n",
    "    \n",
    "    # Calculamos la sparsity\n",
    "    sparsity = 1 - cantidad_no_ceros/total_elementos\n",
    "    \n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "   > __Sparsity para MovieLens:__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"El porcentaje de sparsity de la matriz del dataset MovieLens es: \" + str(sparsity(rating_matrix_movies)* 100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   > __Sparsity para Jester:__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"El porcentaje de sparsity de la matriz del dataset Jester es: \" + str(sparsity(rating_matrix_jokes)* 100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> El <i>sparsity</i> de la matriz de ratings para ambos datasets escogidos da diametralmente distinto, obteniendóse para MovieLens un $sparsity\\_movielens \\approx 98\\%$ y $sparsity\\_jester \\approx 0.36\\%$. Lo anterior indica que, comparando los dos resultados obtenidos, dentro del dataset de __MovieLens__ existe una gran cantidad de usuarios (casi en su totalidad) que han calificado muy pocas películas (y estamos hablando de un dataset de más de 9700 películas), por lo que existirán muchos valores nulos que no aportarán mucho y es más, perjudicarán la precisión de la predicción de las recomendaciones, esto principalmente debido a que al tener películas que tienen por ejemplo un solo usuario que la haya calificado, y que este usuario tenga similaridad con el usuario objetivo, esto podría tender a obtener una recomendación errónea debido a que se está basando en una sola calificación para hacer el cómputo, no así como ocurre con el dataset __Jester__, ya que este presenta un porcentaje casi nulo de sparsity, lo que indica que casi la totalidad de los usuarios contenidos dentro del dataset han calificado la mayoría de las bromas que contiene el dataset (podría de hecho tomarse como una <i>matriz densa</i>, o sea, que la mayoría de sus elementos son no nulos), por lo que, al tener más información con la qué trabajar, la predicción tiene a ser más precisa y confiable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Item based Collaborative Filtering (40 puntos) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La segunda parte de la tarea constará de las siguientes secciones: \n",
    "1. Implementación de un sistema de recomendación de filtro colaborativo basado en ítems utilizando los k ítems más cercanos. Para esta parte, se debe utilizar <b> similaridad coseno </b> como medida de similaridad entre los ítems. Además, el parámetro k debe ser escogido por ustedes. \n",
    "\n",
    "2. Se ingresa nuevo usuario al sistema, se le pide que califique 10 productos (a elección) y a partir de eso se le realiza la recomendación de 5 productos que no ha calificado. Para poder llevar a cabo la recomendación recordar los siguientes pasos:\n",
    "    >a. Se debe generar la matriz de similaridad entre productos basada en la similaridad coseno.\n",
    "    \n",
    "    >b. Para realizar la recomendación, se debe predecir el rating de todos los productos que el usuario nuevo del sistema no haya calificado aún. Para esto, se deben obtener los k ítems más cercanos al ítem a predecir y se debe predecir su rating en base a la <i> weighted sum </i> de los ratings de dichos k ítems. \n",
    "    \n",
    "    >c. Una vez predecidos los ratings para todos los productos sin calificación, se deben recomendar al usuario los 5 productos con mayor rating predecido. \n",
    "\n",
    "3. Concluir y responder las siguientes preguntas: \n",
    "\n",
    "   >a. ¿Cuáles fueron las 5 recomendaciones obtenidas? Analice y concluya respecto a estos resultados.  \n",
    "    \n",
    "   >b. ¿Qué cantidad de vecinos cercanos (k) se escogió para la recomendación? ¿En qué influye la elección de este parámetro? ¿Qué sucede a medida que aumento este parámetro?\n",
    "    \n",
    "   >c. ¿Cuáles son las ventajas de este enfoque respecto al anterior? \n",
    "\n",
    "\n",
    "<i>Importante: Esto debe ser realizado para ambos datasets escogidos</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo P1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos el módulo __NearestNeighbors__ de sklearn, con la métrica de distana coseno para poder predecir luego los ratings del usuario que se ingresará. Se utilizará en primera instancia los 3 vecinos más cercanos y luego ir variando el valor para concluir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_knn(rating_item_matrix, number_neighbors=3):\n",
    "    knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "    knn.fit(rating_item_matrix.values)\n",
    "    \n",
    "    distances, indices = knn.kneighbors(rating_item_matrix.values, n_neighbors=number_neighbors)\n",
    "    \n",
    "    return distances, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted(rating_matrix, user, number_neighbors=3):\n",
    "    copia_aux = rating_matrix.copy()    \n",
    "    user_index = rating_matrix.columns.tolist().index(user)\n",
    "        \n",
    "    distances, indices = item_based_knn(copia_aux,number_neighbors)\n",
    "    #empieza la busqueda de sugerencias\n",
    "    for m,t in list(enumerate(copia_aux.index)):\n",
    "\n",
    "          # se encuentran libros sin calificar de usuario\n",
    "            if copia_aux.iloc[m, user_index] == 0:\n",
    "                similar_items = indices[m].tolist()\n",
    "                items_distances = distances[m].tolist()\n",
    "\n",
    "            #se saca el libro de las similitudes. \n",
    "            if m in similar_items:\n",
    "                item_id = similar_items.index(m)\n",
    "                similar_items.remove(m)\n",
    "                items_distances.pop(item_id) \n",
    "\n",
    "            # si existen muchos ceros a vecinos cercanos se sacan los vecinos mas lejanos.\n",
    "            else:\n",
    "                similar_items = similar_items[:number_neighbors-1]\n",
    "                items_distances = items_distances[:number_neighbors-1]\n",
    "\n",
    "\n",
    "            item_similarity = [1-x for x in items_distances]\n",
    "            item_similarity_copy = item_similarity.copy()\n",
    "            nominator = 0\n",
    "\n",
    "            # para cada libro similar\n",
    "            for s in range(0, len(item_similarity)):\n",
    "\n",
    "              # vemos si valor es cero\n",
    "                if copia_aux.iloc[similar_items[s], user_index] == 0:\n",
    "\n",
    "                # de ser cero se ignora\n",
    "                    if len(item_similarity_copy) == (number_neighbors - 1):\n",
    "                        item_similarity_copy.pop(s)\n",
    "\n",
    "                    else:\n",
    "                        item_similarity_copy.pop(s-(len(item_similarity)-len(item_similarity_copy)))\n",
    "\n",
    "                else:\n",
    "                    nominator = nominator + item_similarity[s]*copia_aux.iloc[similar_items[s],user_index]\n",
    "            if len(item_similarity_copy) > 0:\n",
    "                if sum(item_similarity_copy) > 0:\n",
    "                    predicted_r = nominator/sum(item_similarity_copy)\n",
    "                else:\n",
    "                    predicted_r = 0\n",
    "            else:\n",
    "                predicted_r = 0\n",
    "            copia_aux.iloc[m,user_index] = predicted_r\n",
    "            \n",
    "    #la copia del la matriz, copia_aux, actualiza todas las predicciones para el usuario user       \n",
    "    return copia_aux\n",
    "\n",
    "def item_recom(rating_matrix, user, num_recommended_items,dataset, number_neighbors=3):\n",
    "    copia_aux = get_predicted(rating_matrix, user, number_neighbors)\n",
    "    \n",
    "    recommended_items = []\n",
    "\n",
    "    for m in rating_matrix[rating_matrix[user] == 0].index.tolist():\n",
    "\n",
    "        index_rating = rating_matrix.index.tolist().index(m)\n",
    "        predicted_rating = copia_aux.iloc[index_rating, copia_aux.columns.tolist().index(user)]\n",
    "        recommended_items.append((m, predicted_rating))\n",
    "\n",
    "    sorted_rm = sorted(recommended_items, key=lambda x:x[1], reverse=True)\n",
    "      \n",
    "    if dataset == 'movielens':\n",
    "        print('Películas recomendadas para el usuario de id: {}\\n'.format(user))\n",
    "        rank = 1\n",
    "        for recommended_items in sorted_rm[:num_recommended_items]:\n",
    "            movie =  df_movies[df_movies['movie_id'] == recommended_items[0]]['title'].item()\n",
    "            rating = recommended_items[1]        \n",
    "            print('{}: {} - predicción: {}'.format(rank, movie, rating))\n",
    "            rank = rank + 1\n",
    "            \n",
    "    elif dataset == 'jester':\n",
    "        print('Chistes recomendados para el usuario de id: {}\\n'.format(user))\n",
    "        rank = 1\n",
    "        for recommended_items in sorted_rm[:num_recommended_items]:\n",
    "            joke =  df_jokes[df_jokes['joke_id'] == recommended_items[0]]['joke_text'].item()\n",
    "            rating = recommended_items[1]        \n",
    "            print('{}: {} - predicción: {}'.format(rank, joke, rating))\n",
    "            rank = rank + 1\n",
    "            print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MovieLens\n",
    "\n",
    "Igual que en el UBCF, utilizaremos las funciones creadas ahí para que un usuario nuevo califique 5 películas, para luego utilizar el item_based_knn sobre el nuevo df, entonces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "movies_with_new_rating = rate_10_products('movielens')\n",
    "movies_with_new_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_matrix_item_ML = movies_with_new_rating.pivot_table(index = 'movie_id',columns = 'user_id', values = 'rating').fillna(0)\n",
    "display(rating_matrix_item_ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_recom(rating_matrix_item_ML, 611, 5,'movielens',number_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_recom(rating_matrix_item_ML, 611, 5,'movielens',number_neighbors=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_recom(rating_matrix_item_ML, 611, 5,'movielens',number_neighbors=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_recom(rating_matrix_item_ML, 611, 5,'movielens',number_neighbors=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jester\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jokes_with_new_rating = rate_10_products('jester')\n",
    "jokes_with_new_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_matrix_item_JT_new = jokes_with_new_rating.pivot_table(index = 'joke_id',columns = 'user_id', values = 'rating').fillna(0)\n",
    "display(rating_matrix_item_JT_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_recom(rating_matrix_item_JT_new, 2000, 5,'jester',number_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_recom(rating_matrix_item_JT_new, 2000, 5,'jester',number_neighbors=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_recom(rating_matrix_item_JT_new, 2000, 5,'jester',number_neighbors=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_recom(rating_matrix_item_JT_new, 2000, 5,'jester',number_neighbors=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La segunda parte de la tarea constará de las siguientes secciones: \n",
    "1. Implementación de un sistema de recomendación de filtro colaborativo basado en ítems utilizando los k ítems más cercanos. Para esta parte, se debe utilizar <b> similaridad coseno </b> como medida de similaridad entre los ítems. Además, el parámetro k debe ser escogido por ustedes. \n",
    "\n",
    "2. Se ingresa nuevo usuario al sistema, se le pide que califique 10 productos (a elección) y a partir de eso se le realiza la recomendación de 5 productos que no ha calificado. Para poder llevar a cabo la recomendación recordar los siguientes pasos:\n",
    "    >a. Se debe generar la matriz de similaridad entre productos basada en la similaridad coseno.\n",
    "    \n",
    "    >b. Para realizar la recomendación, se debe predecir el rating de todos los productos que el usuario nuevo del sistema no haya calificado aún. Para esto, se deben obtener los k ítems más cercanos al ítem a predecir y se debe predecir su rating en base a la <i> weighted sum </i> de los ratings de dichos k ítems. \n",
    "    \n",
    "    >c. Una vez predecidos los ratings para todos los productos sin calificación, se deben recomendar al usuario los 5 productos con mayor rating predecido. \n",
    "\n",
    "## 3. Concluir y responder las siguientes preguntas: \n",
    "\n",
    "   >a. ¿Cuáles fueron las 5 recomendaciones obtenidas? Analice y concluya respecto a estos resultados.  \n",
    "    \n",
    "   >b. ¿Qué cantidad de vecinos cercanos (k) se escogió para la recomendación? ¿En qué influye la elección de este parámetro? ¿Qué sucede a medida que aumento este parámetro?\n",
    "    \n",
    "   >c. ¿Cuáles son las ventajas de este enfoque respecto al anterior? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.- \n",
    "Con un k inicial de 3 vecinos cercanos estos fueron los resultados para ambos dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_recom(rating_matrix_item_ML, 611, 5,'movielens',number_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_recom(rating_matrix_item_JT_new, 2000, 5,'jester',number_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que podemos ver es que en ambos casos los valores de predicción son o muy buenos o muy malos, esto se debe al pequeño tamaño de muestra de donde se sacan estas recomendaciones. Por lo que se espera que a una muestra de mayor tamaño esto cambie y existan valores medios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.- \n",
    "Luego de una variacíon de los k vecinos, podemos ver que para ambos dataset al momento de aumentar el k existen recomendaciones que siguen apareciendo, aunque son pocas. Lo que si ocurre es que las recomendaciones a medida que se ven mas vecinos los valores de predicción de las sugerencias bajan pero se \"estabilizan\" al comparar con más opciones, por lo que la sugerecia deja de ser o muy buena o muy mala y entra a valores medios, como en el caso de lso chistes con k = 50 que los valores de predicción tiende a 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.- \n",
    "La precisión de predicción es mejor en item based que en user based, además que mas fácil de explicar al usuario de donde viene la sugerencia. La consistencia de la sugerencia es mejor ya que se calcula respecto al puntaje de el mismo usuario. Otro factor de ventaja es que factor Sparsity del otro metodo, ya que el ratio de personas que evaluan items es muy bajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusiones finales (20 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Analice los resultados obtenidos y contraste ambos enfoques (ubcf y ibcf). \n",
    "2. Analice ventajas y desventajas de ambos enfoques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.- \n",
    "Como se pudo ver a lo largo del escrito, podemos ver que los resultados entregados por ubcf son poco variables ya que la sparsity por ejemplo del dataset movies, es muy alta, del 98%, lo que nos dice que la evaluación por parte de los users es muy baja, lo que afecta a la calidad de recomendación. \n",
    "\n",
    "2.- \n",
    "La ventaja de ubcf la variedad de sugerencias crece a medida que aumenta la cantidad de vecinos que se comparan. El gran problema de este enfoque es el valor del sparsity y como consecuencia el comienzo de los dataset, ya que al iniciar los datos las calificaciones son practicamente nulas, lo que afecta el sistema de sugerencias. Relacionado con lo anterior existe el problema de la escalabilidad.\n",
    "\n",
    "Ibcf:\n",
    "Since the ratings are predicted using the ratings of user herself, the predicted ratings tend to be much more consistent with the other ratings\n",
    "of this user.\n",
    "Item based similarity is a common choice for high load services.\n",
    ">> The reason is that usually item’s neighbourhood changes much slower in compared to user’s neighbourhood.\n",
    "Much easier to explain the recommendation to the users.\n",
    "Item-based recommenders perform considerably better than the user-based ones.\n",
    "The greater prediction accuracy of the item-based method is its main advantage.\n",
    "Item-based methods are also more robust to shilling attacks\n",
    "in recommender systems.\n",
    "\n",
    "Item-based methods might sometimes recommend obvious items, or items which are not novel from previous user experiences.\n",
    "LSA has an overall negative effect on the item-based recommendations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
